{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"PreprocessedDataTrain.csv\")\n",
    "test = pd.read_csv(\"PreprocessedDataTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>Category</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>cleaned_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "      <td>also ronald asmus policy entrepreneur fellow g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>accountant</td>\n",
       "      <td>member aicpa wicpa brent graduated university ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "      <td>dr aster held teaching research positions ben ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>He runs a boutique design studio attending cl...</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>architect</td>\n",
       "      <td>runs boutique design studio attending clients ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>He focuses on cloud security, identity and ac...</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>architect</td>\n",
       "      <td>focuses cloud security identity access managem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                        description gender  Category  \\\n",
       "0   0   She is also a Ronald D. Asmus Policy Entrepre...      F        19   \n",
       "1   1   He is a member of the AICPA and WICPA. Brent ...      M         9   \n",
       "2   2   Dr. Aster has held teaching and research posi...      M        19   \n",
       "3   3   He runs a boutique design studio attending cl...      M        24   \n",
       "4   4   He focuses on cloud security, identity and ac...      M        24   \n",
       "\n",
       "     jobtitle                                       cleaned_Data  \n",
       "0   professor  also ronald asmus policy entrepreneur fellow g...  \n",
       "1  accountant  member aicpa wicpa brent graduated university ...  \n",
       "2   professor  dr aster held teaching research positions ben ...  \n",
       "3   architect  runs boutique design studio attending clients ...  \n",
       "4   architect  focuses cloud security identity access managem...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>cleaned_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She currently works on CNN’s newest primetime...</td>\n",
       "      <td>F</td>\n",
       "      <td>currently works cnns newest primetime show par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lavalette’s photographs have been shown widel...</td>\n",
       "      <td>M</td>\n",
       "      <td>lavalettes photographs shown widely editorial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Along with his academic and professional deve...</td>\n",
       "      <td>M</td>\n",
       "      <td>along academic professional development gabrie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>She obtained her Ph.D. in Islamic Studies at ...</td>\n",
       "      <td>F</td>\n",
       "      <td>obtained phd islamic studies duke university s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>She studies issues of women and Islam and has...</td>\n",
       "      <td>F</td>\n",
       "      <td>studies issues women islam written polygamy am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                        description gender  \\\n",
       "0   0   She currently works on CNN’s newest primetime...      F   \n",
       "1   1   Lavalette’s photographs have been shown widel...      M   \n",
       "2   2   Along with his academic and professional deve...      M   \n",
       "3   3   She obtained her Ph.D. in Islamic Studies at ...      F   \n",
       "4   4   She studies issues of women and Islam and has...      F   \n",
       "\n",
       "                                        cleaned_Data  \n",
       "0  currently works cnns newest primetime show par...  \n",
       "1  lavalettes photographs shown widely editorial ...  \n",
       "2  along academic professional development gabrie...  \n",
       "3  obtained phd islamic studies duke university s...  \n",
       "4  studies issues women islam written polygamy am...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import transformers\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 23\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mislabeled = train.groupby(['cleaned_Data']).nunique().sort_values(by='jobtitle', ascending=False)\n",
    "df_mislabeled = df_mislabeled[df_mislabeled['jobtitle'] > 1]['jobtitle']\n",
    "df_mislabeled = df_mislabeled.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_dup_rows = train['cleaned_Data'].isin(df_mislabeled)\n",
    "train = train[~drop_dup_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc789ff8792a402b8cf784ee922d0fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=train['cleaned_Data'].values,train['Category'].values\n",
    "\n",
    "for tr_idx,te_idx in sss.split(X,y):\n",
    "  X_train = X[tr_idx]\n",
    "  y_train = y[tr_idx]\n",
    "  X_test = X[te_idx]\n",
    "  y_test = y[te_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_input_features(tokenizer, docs, max_seq_length):\n",
    "  \n",
    "  all_ids, all_masks, all_segments= [], [], []\n",
    "  for doc in tqdm.tqdm(docs, desc=\"Converting docs to features\"):\n",
    "      \n",
    "      tokens = tokenizer.tokenize(doc)\n",
    "      \n",
    "      if len(tokens) > max_seq_length-2:\n",
    "          tokens = tokens[0 : (max_seq_length-2)]\n",
    "      tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "      ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "      masks = [1] * len(ids)\n",
    "      \n",
    "      # Zero-pad up to the sequence length.\n",
    "      while len(ids) < max_seq_length:\n",
    "          ids.append(0)\n",
    "          masks.append(0)\n",
    "          \n",
    "      segments = [0] * max_seq_length\n",
    "      all_ids.append(ids)\n",
    "      all_masks.append(masks)\n",
    "      all_segments.append(segments)\n",
    "      \n",
    "  encoded = np.array([all_ids, all_masks, all_segments])\n",
    "  \n",
    "  return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_SEQ_LENGTH = 60\n",
    "\n",
    "inp_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_ids\")\n",
    "inp_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_input_masks\")\n",
    "inp_segment = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), dtype='int32', name=\"bert_segment_ids\")\n",
    "inputs = [inp_id, inp_mask, inp_segment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fb418278664157a32cb0b30ea75bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=433.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20625b42d7cd45f5a08782d8baacd440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=536063208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "hidden_state = transformers.TFBertModel.from_pretrained('bert-base-uncased')(inputs)\n",
    "pooled_output = hidden_state[1]\n",
    "dense1 = tf.keras.layers.Dense(256, activation='relu')(pooled_output)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "output = tf.keras.layers.Dense(28, activation='softmax')(drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08),loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'C:/Users/yoges/MachineLearningProject/bert_t.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-20c4f4dcc36f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/yoges/MachineLearningProject/bert_t.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2204\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2205\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'C:/Users/yoges/MachineLearningProject/bert_t.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights('C:/Users/yoges/MachineLearningProject/bert_t.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "bert_input_ids (InputLayer)     [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_input_masks (InputLayer)   [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_segment_ids (InputLayer)   [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 60, 768), (N 109482240   bert_input_ids[0][0]             \n",
      "                                                                 bert_input_masks[0][0]           \n",
      "                                                                 bert_segment_ids[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 28)           7196        dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,752,092\n",
      "Trainable params: 109,752,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:5000]\n",
    "y_val = y_train[:5000]\n",
    "X_train_ = X_train[5000:]\n",
    "y_train_ = y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to features: 100%|████████████████████████████████████████████████████████████████████████| 157877/157877 [02:22<00:00, 1109.30it/s]\n",
      "Converting docs to features: 100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:04<00:00, 1114.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: (157877, 60) (157877, 60) (157877, 60)\n",
      "Val Features: (5000, 60) (5000, 60) (5000, 60)\n",
      "12145/12145 [==============================] - 2434s 200ms/step - loss: 0.7995 - accuracy: 0.7829 - val_loss: 0.5818 - val_accuracy: 0.8372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to features:   0%|▎                                                                           | 213/54293 [00:00<00:50, 1081.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning is over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting docs to features: 100%|██████████████████████████████████████████████████████████████████████████| 54293/54293 [00:49<00:00, 1087.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1697/1697 [==============================] - 229s 135ms/step\n",
      "initial pred\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       374\n",
      "           1       0.90      0.71      0.79      1029\n",
      "           2       0.62      0.86      0.72       236\n",
      "           3       0.62      0.60      0.61      2286\n",
      "           4       0.79      0.70      0.74       202\n",
      "           5       0.84      0.80      0.82      1155\n",
      "           6       0.76      0.76      0.76      3074\n",
      "           7       0.63      0.76      0.69       214\n",
      "           8       0.86      0.68      0.76      1653\n",
      "           9       0.82      0.76      0.79       780\n",
      "          10       0.72      0.73      0.73       208\n",
      "          11       0.71      0.77      0.73      2901\n",
      "          12       0.83      0.80      0.82       410\n",
      "          13       0.72      0.75      0.73      1015\n",
      "          14       0.95      0.79      0.86      3155\n",
      "          15       0.81      0.74      0.77      1073\n",
      "          16       0.94      0.91      0.92      1361\n",
      "          17       0.88      0.53      0.66       350\n",
      "          18       0.82      0.79      0.80      1031\n",
      "          19       0.86      0.94      0.90     17503\n",
      "          20       0.84      0.89      0.87      3662\n",
      "          21       0.92      0.67      0.78       196\n",
      "          22       0.80      0.72      0.76      2597\n",
      "          23       0.72      0.58      0.65       242\n",
      "          24       0.73      0.66      0.70      1460\n",
      "          25       0.82      0.83      0.83       849\n",
      "          26       0.90      0.88      0.89      4705\n",
      "          27       0.88      0.79      0.83       572\n",
      "\n",
      "    accuracy                           0.83     54293\n",
      "   macro avg       0.80      0.75      0.77     54293\n",
      "weighted avg       0.83      0.83      0.83     54293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features_ids, train_features_masks, train_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                               X_train_, \n",
    "                                                                                               max_seq_length=MAX_SEQ_LENGTH)\n",
    "val_features_ids, val_features_masks, val_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                         X_val, \n",
    "                                                                                         max_seq_length=MAX_SEQ_LENGTH)\n",
    "#test_features = create_bert_input_features(tokenizer, test_reviews, max_seq_length=MAX_SEQ_LENGTH)\n",
    "print('Train Features:', train_features_ids.shape, train_features_masks.shape, train_features_segments.shape)\n",
    "print('Val Features:', val_features_ids.shape, val_features_masks.shape, val_features_segments.shape)\n",
    "\n",
    "check_point = tf.keras.callbacks.ModelCheckpoint('/home/deepakumar_msc/check_point/bert_t_1.h5',save_best_only=True,save_weights_only=True)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n",
    "\n",
    "model.fit([train_features_ids, \n",
    "           train_features_masks, \n",
    "           train_features_segments], y_train_, \n",
    "          validation_data=([val_features_ids, \n",
    "                            val_features_masks, \n",
    "                            val_features_segments], y_val),\n",
    "          epochs=1, \n",
    "          batch_size=13, \n",
    "          callbacks=[check_point,early_stopping],\n",
    "          shuffle=True,verbose=1)#,\n",
    "          #verbose=1)\n",
    "\n",
    "print('learning is over')\n",
    "\n",
    "\n",
    "test_features_ids, test_features_masks, test_features_segments = create_bert_input_features(tokenizer, \n",
    "                                                                                         X_test, \n",
    "                                                                                         max_seq_length=MAX_SEQ_LENGTH)\n",
    "\n",
    "y_hat = model.predict([test_features_ids,test_features_masks,test_features_segments], verbose=1)\n",
    "\n",
    "y_hat = np.argmax(y_hat,axis=1)\n",
    "\n",
    "print('initial pred')\n",
    "\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
