{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tensorflow.keras.layers import Dropout, Dense, GRU, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_Tokenizer(X_train, X_valid,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=60):\n",
    "    np.random.seed(1)\n",
    "    text = np.concatenate((X_train, X_valid), axis=0)\n",
    "    text = np.array(text)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    indices = np.arange(text.shape[0])\n",
    "    # np.random.shuffle(indices)\n",
    "    text = text[indices]\n",
    "    print(text.shape)\n",
    "    X_train = text[0:len(X_train), ]\n",
    "    X_valid = text[len(X_train):, ]\n",
    "    embeddings_index = {}\n",
    "    f = open(\"C:\\\\Users\\\\yoges\\\\MachineLearningProject\\\\Glove\\\\glove.6B.50d.txt\", encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            pass\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    return (X_train, X_valid, word_index,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_Tokenizer_test(X_test,MAX_NB_WORDS=75000,MAX_SEQUENCE_LENGTH=60):\n",
    "    np.random.seed(1)\n",
    "    text = np.array(X_test)\n",
    "    tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    word_index = tokenizer.word_index\n",
    "    text = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    indices = np.arange(text.shape[0])\n",
    "    # np.random.shuffle(indices)\n",
    "    text = text[indices]\n",
    "    print(text.shape)\n",
    "    X_test = text\n",
    "    embeddings_index = {}\n",
    "    f = open(\"C:\\\\Users\\\\yoges\\\\MachineLearningProject\\\\Glove\\\\glove.6B.50d.txt\", encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            pass\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print('Total %s word vectors.' % len(embeddings_index))\n",
    "    return (X_test, word_index,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Model_RNN_Text(word_index, embeddings_index, nclasses,  MAX_SEQUENCE_LENGTH=60, EMBEDDING_DIM=50, dropout=0.45):\n",
    "    \"\"\"\n",
    "    def buildModel_RNN(word_index, embeddings_index, nclasses,  MAX_SEQUENCE_LENGTH=500, EMBEDDING_DIM=50, dropout=0.5):\n",
    "    word_index in word index ,\n",
    "    embeddings_index is embeddings index, look at data_helper.py\n",
    "    nClasses is number of classes,\n",
    "    MAX_SEQUENCE_LENGTH is maximum lenght of text sequences\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    hidden_layer = 3\n",
    "    gru_node = 32\n",
    "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            if len(embedding_matrix[i]) != len(embedding_vector):\n",
    "                print(\"could not broadcast input array from shape\", str(len(embedding_matrix[i])),\n",
    "                      \"into shape\", str(len(embedding_vector)), \" Please make sure your\"\n",
    "                                                                \" EMBEDDING_DIM is equal to embedding_vector file ,GloVe,\")\n",
    "                exit(1)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                trainable=True))\n",
    "    print(gru_node)\n",
    "    for i in range(0,hidden_layer):\n",
    "        model.add(GRU(gru_node,return_sequences=True, recurrent_dropout=0.2))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(GRU(gru_node, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(nclasses, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>Category</th>\n",
       "      <th>jobtitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>She is also a Ronald D. Asmus Policy Entrepre...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is a member of the AICPA and WICPA. Brent ...</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Dr. Aster has held teaching and research posi...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>He runs a boutique design studio attending cl...</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>He focuses on cloud security, identity and ac...</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217192</th>\n",
       "      <td>217192</td>\n",
       "      <td>A member of the UWA Cultural Collections Boar...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217193</th>\n",
       "      <td>217193</td>\n",
       "      <td>Kelly has worked globally leading teams of co...</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>psychologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217194</th>\n",
       "      <td>217194</td>\n",
       "      <td>He's the lead author of a recent study that f...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217195</th>\n",
       "      <td>217195</td>\n",
       "      <td>She specializes in the theoretical and pedago...</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217196</th>\n",
       "      <td>217196</td>\n",
       "      <td>Since she was 10 years old she has become a m...</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                        description gender  \\\n",
       "0            0   She is also a Ronald D. Asmus Policy Entrepre...      F   \n",
       "1            1   He is a member of the AICPA and WICPA. Brent ...      M   \n",
       "2            2   Dr. Aster has held teaching and research posi...      M   \n",
       "3            3   He runs a boutique design studio attending cl...      M   \n",
       "4            4   He focuses on cloud security, identity and ac...      M   \n",
       "...        ...                                                ...    ...   \n",
       "217192  217192   A member of the UWA Cultural Collections Boar...      M   \n",
       "217193  217193   Kelly has worked globally leading teams of co...      F   \n",
       "217194  217194   He's the lead author of a recent study that f...      M   \n",
       "217195  217195   She specializes in the theoretical and pedago...      F   \n",
       "217196  217196   Since she was 10 years old she has become a m...      F   \n",
       "\n",
       "        Category      jobtitle  \n",
       "0             19     professor  \n",
       "1              9    accountant  \n",
       "2             19     professor  \n",
       "3             24     architect  \n",
       "4             24     architect  \n",
       "...          ...           ...  \n",
       "217192        19     professor  \n",
       "217193        22  psychologist  \n",
       "217194        19     professor  \n",
       "217195        19     professor  \n",
       "217196         1         model  \n",
       "\n",
       "[217197 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "labels = pd.read_csv(\"categories_string.csv\")\n",
    "train_label= pd.read_csv('train_label.csv')\n",
    "with open('train.json') as f:\n",
    "   train = json.load(f)\n",
    "with open('test.json') as h:\n",
    "   test = json.load(h)\n",
    "\n",
    "train_df = pd.DataFrame(train)\n",
    "test_df = pd.DataFrame(test)\n",
    "dic = labels.to_dict()\n",
    "dic = dic[\"0\"]\n",
    "train_label['jobtitle'] = train_label['Category']\n",
    "train_label = train_label.replace({\"jobtitle\": dic})\n",
    "comb_data = pd.merge(train_df,train_label,how = \"outer\", on = 'Id' )\n",
    "comb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mismatch = comb_data.groupby('description').nunique().sort_values('jobtitle')\n",
    "df_mismatch = df_mismatch[df_mismatch['jobtitle']>1]\n",
    "df_mismatch = df_mismatch.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' He is an in-network provider for Blue Cross Blue Shield EPO, Blue Cross Blue Shield Bronze, and Blue Cross Blue Shield HMO, as well as other insurance carriers.',\n",
       " ' More information on property rights is available at www.mackinac.org. Permission to reprint in whole or in part is hereby granted, provided the author and his affiliations are cited.)',\n",
       " ' She was in clinical practice in UAB’s Transfusion Medicine for 7 years prior to joining the School of Health Professions in 2010.Ms. Miller received her undergraduate Bachelor of Science degree in Biology from Judson College (2002) and her Master of Science degree in Clinical Laboratory Science from the University of Alabama at Birmingham (2004). She holds a current certification from American Society for Clinical Pathology (ASCP).',\n",
       " ' He obtained his MSc (Dalhousie University) and PhD in Pharmacy (University of British Columbia) and went on to medical school in Toronto. He subsequently trained as a general thoracic and vascular surgeon. He has keen interests in drug safety and is an avid medical writer, with numerous continuation education modules for physicians and allied healthcare professionals.',\n",
       " ' He is an in-network provider for Blue Cross/Blue Shield, Blue Cross Blue Shield Bronze, and Blue Cross Blue Shield HMO, in addition to other insurance carriers.',\n",
       " ' She is an in-network provider for Blue Cross/Blue Shield, Blue Cross Blue Shield Bronze, and Blue Cross Blue Shield HMO, in addition to other insurance carriers.',\n",
       " ' He provides care for patients suffering from work related injuries and musculoskeletal conditions. All of the providers at NMCI Medical Clinic work as a team with the goal of improving the patient’s overall health and well being.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_condition = comb_data['description'].isin(df_mismatch)\n",
    "comb_data = comb_data[~filter_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217175, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "      <th>Category</th>\n",
       "      <th>jobtitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>4295</td>\n",
       "      <td>Her stories have appeared in The Chronicle of...</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>journalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173903</th>\n",
       "      <td>173903</td>\n",
       "      <td>His research interests are in statistical asp...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132585</th>\n",
       "      <td>132585</td>\n",
       "      <td>A newcomer to politics, Prince said she was i...</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29929</th>\n",
       "      <td>29929</td>\n",
       "      <td>He received his PhD in Economics from the Uni...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24611</th>\n",
       "      <td>24611</td>\n",
       "      <td>His research focuses on educational policy fo...</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168053</th>\n",
       "      <td>168053</td>\n",
       "      <td>She is interested in shaping international kn...</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143255</th>\n",
       "      <td>143255</td>\n",
       "      <td>Whilst he’s literally putting his hometown on...</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>dj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148201</th>\n",
       "      <td>148201</td>\n",
       "      <td>Fleischer began her career in photography as ...</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>photographer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81599</th>\n",
       "      <td>81599</td>\n",
       "      <td>Her hospital/clinic affiliations include Nort...</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>physician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98173</th>\n",
       "      <td>98173</td>\n",
       "      <td>Most of the work hanging in his studio leans ...</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>photographer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                        description gender  \\\n",
       "4295      4295   Her stories have appeared in The Chronicle of...      F   \n",
       "173903  173903   His research interests are in statistical asp...      M   \n",
       "132585  132585   A newcomer to politics, Prince said she was i...      F   \n",
       "29929    29929   He received his PhD in Economics from the Uni...      M   \n",
       "24611    24611   His research focuses on educational policy fo...      M   \n",
       "...        ...                                                ...    ...   \n",
       "168053  168053   She is interested in shaping international kn...      F   \n",
       "143255  143255   Whilst he’s literally putting his hometown on...      M   \n",
       "148201  148201   Fleischer began her career in photography as ...      F   \n",
       "81599    81599   Her hospital/clinic affiliations include Nort...      F   \n",
       "98173    98173   Most of the work hanging in his studio leans ...      M   \n",
       "\n",
       "        Category      jobtitle  \n",
       "4295           6    journalist  \n",
       "173903        19     professor  \n",
       "132585        14         nurse  \n",
       "29929         19     professor  \n",
       "24611         19     professor  \n",
       "...          ...           ...  \n",
       "168053         3       teacher  \n",
       "143255        10            dj  \n",
       "148201        20  photographer  \n",
       "81599         11     physician  \n",
       "98173         20  photographer  \n",
       "\n",
       "[217175 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_data= comb_data.reindex(np.random.permutation(comb_data.index))\n",
    "shuffled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>She currently works on CNN’s newest primetime...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Lavalette’s photographs have been shown widel...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Along with his academic and professional deve...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>She obtained her Ph.D. in Islamic Studies at ...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>She studies issues of women and Islam and has...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271476</th>\n",
       "      <td>54295</td>\n",
       "      <td>Prior to that, she worked as a Research Staff...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271477</th>\n",
       "      <td>54296</td>\n",
       "      <td>The group’s antics began when they switched t...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271482</th>\n",
       "      <td>54297</td>\n",
       "      <td>Formerly, she was the Coordinator for Music E...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271485</th>\n",
       "      <td>54298</td>\n",
       "      <td>She started her law practice at Morris Mannin...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271486</th>\n",
       "      <td>54299</td>\n",
       "      <td>Since 1995, he works as a programme maker and...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                        description gender\n",
       "3           0   She currently works on CNN’s newest primetime...      F\n",
       "6           1   Lavalette’s photographs have been shown widel...      M\n",
       "11          2   Along with his academic and professional deve...      M\n",
       "17          3   She obtained her Ph.D. in Islamic Studies at ...      F\n",
       "18          4   She studies issues of women and Islam and has...      F\n",
       "...       ...                                                ...    ...\n",
       "271476  54295   Prior to that, she worked as a Research Staff...      F\n",
       "271477  54296   The group’s antics began when they switched t...      M\n",
       "271482  54297   Formerly, she was the Coordinator for Music E...      F\n",
       "271485  54298   She started her law practice at Morris Mannin...      F\n",
       "271486  54299   Since 1995, he works as a programme maker and...      M\n",
       "\n",
       "[54300 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>description</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225005</th>\n",
       "      <td>45147</td>\n",
       "      <td>She established a nonprofit human rights orga...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19524</th>\n",
       "      <td>3873</td>\n",
       "      <td>Three years ago, she was approached by her pr...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224588</th>\n",
       "      <td>45065</td>\n",
       "      <td>Dr. Sumedh Dawane practices at Dr. Hitesh Swa...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129782</th>\n",
       "      <td>26008</td>\n",
       "      <td>His international experience includes various...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64394</th>\n",
       "      <td>12756</td>\n",
       "      <td>She graduated with honors in 1990. Having mor...</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231596</th>\n",
       "      <td>46450</td>\n",
       "      <td>He received his M.Sc. degree in Computer Scie...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262507</th>\n",
       "      <td>52552</td>\n",
       "      <td>Whether he is producing a conventional painti...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11970</th>\n",
       "      <td>2357</td>\n",
       "      <td>He has resolved disputes and crafted deals fo...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220585</th>\n",
       "      <td>44294</td>\n",
       "      <td>He deals mostly in small civil cases, but Jay...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252746</th>\n",
       "      <td>50639</td>\n",
       "      <td>Prior, he was a Postdoctoral researcher in th...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                        description gender\n",
       "225005  45147   She established a nonprofit human rights orga...      F\n",
       "19524    3873   Three years ago, she was approached by her pr...      F\n",
       "224588  45065   Dr. Sumedh Dawane practices at Dr. Hitesh Swa...      M\n",
       "129782  26008   His international experience includes various...      M\n",
       "64394   12756   She graduated with honors in 1990. Having mor...      F\n",
       "...       ...                                                ...    ...\n",
       "231596  46450   He received his M.Sc. degree in Computer Scie...      M\n",
       "262507  52552   Whether he is producing a conventional painti...      M\n",
       "11970    2357   He has resolved disputes and crafted deals fo...      M\n",
       "220585  44294   He deals mostly in small civil cases, but Jay...      M\n",
       "252746  50639   Prior, he was a Postdoctoral researcher in th...      M\n",
       "\n",
       "[54300 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_test_data = test_df.reindex(np.random.permutation(test_df.index))\n",
    "shuffled_test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = shuffled_data['description']\n",
    "y = shuffled_data['Category']\n",
    "\n",
    "X_test = shuffled_test_data['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train ,y_valid = train_test_split(X, y,stratify=y, test_size=0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173740,)\n",
      "(173740,)\n",
      "(43435,)\n",
      "(43435,)\n",
      "(54300,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272164 unique tokens.\n",
      "(217175, 60)\n",
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "X_train_Glove,X_valid_Glove, word_index,embeddings_index = loadData_Tokenizer(X_train,X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 113608 unique tokens.\n",
      "(54300, 60)\n",
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "X_test_Glove = loadData_Tokenizer_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 60, 50)            13608250  \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 60, 32)            8064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 60, 32)            6336      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 60, 32)            6336      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 32)                6336      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 13,650,966\n",
      "Trainable params: 13,650,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_RNN = Build_Model_RNN_Text(word_index,embeddings_index, 28)\n",
    "print(model_RNN.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "checkpoint_path='C:\\\\Users\\\\yoges\\\\MachineLearningProject\\\\rnn_weights.h5'\n",
    "\n",
    "\n",
    "keras_callbacks   = [\n",
    "      EarlyStopping(monitor='val_loss', patience=4),\n",
    "      ModelCheckpoint(checkpoint_path,save_weights_only=True ,save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21718/21718 - 14954s - loss: 1.3239 - accuracy: 0.6204 - val_loss: 0.9086 - val_accuracy: 0.7430\n",
      "Epoch 2/10\n",
      "21718/21718 - 14740s - loss: 0.9635 - accuracy: 0.7309 - val_loss: 0.8756 - val_accuracy: 0.7591\n",
      "Epoch 3/10\n",
      "21718/21718 - 14684s - loss: 0.8507 - accuracy: 0.7639 - val_loss: 0.8490 - val_accuracy: 0.7697\n",
      "Epoch 4/10\n",
      "21718/21718 - 14645s - loss: 0.7640 - accuracy: 0.7876 - val_loss: 0.8850 - val_accuracy: 0.7590\n",
      "Epoch 5/10\n",
      "21718/21718 - 14818s - loss: 0.6907 - accuracy: 0.8089 - val_loss: 0.9371 - val_accuracy: 0.7635\n",
      "Epoch 6/10\n",
      "21718/21718 - 16588s - loss: 0.6309 - accuracy: 0.8261 - val_loss: 0.9699 - val_accuracy: 0.7590\n",
      "Epoch 7/10\n",
      "21718/21718 - 14705s - loss: 0.5781 - accuracy: 0.8417 - val_loss: 1.0864 - val_accuracy: 0.7538\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model_RNN.fit(X_train_Glove, y_train,\n",
    "                              validation_data=(X_valid_Glove, y_valid),\n",
    "                              epochs=10,\n",
    "                              batch_size=8,verbose=2,callbacks=keras_callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_RNN.predict(X_valid_Glove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39       299\n",
      "           1       0.80      0.66      0.72       823\n",
      "           2       0.63      0.59      0.61       189\n",
      "           3       0.48      0.58      0.53      1829\n",
      "           4       0.50      0.57      0.53       161\n",
      "           5       0.66      0.75      0.70       924\n",
      "           6       0.64      0.66      0.65      2459\n",
      "           7       0.52      0.38      0.44       172\n",
      "           8       0.75      0.70      0.73      1323\n",
      "           9       0.65      0.70      0.68       624\n",
      "          10       0.55      0.58      0.56       166\n",
      "          11       0.69      0.68      0.68      2321\n",
      "          12       0.54      0.71      0.61       328\n",
      "          13       0.63      0.61      0.62       812\n",
      "          14       0.88      0.77      0.82      2524\n",
      "          15       0.64      0.64      0.64       858\n",
      "          16       0.92      0.91      0.92      1089\n",
      "          17       0.61      0.63      0.62       280\n",
      "          18       0.63      0.70      0.67       825\n",
      "          19       0.87      0.83      0.85     14003\n",
      "          20       0.80      0.81      0.81      2929\n",
      "          21       0.45      0.57      0.50       157\n",
      "          22       0.70      0.68      0.69      2078\n",
      "          23       0.71      0.41      0.52       193\n",
      "          24       0.60      0.61      0.60      1168\n",
      "          25       0.72      0.79      0.75       679\n",
      "          26       0.82      0.84      0.83      3764\n",
      "          27       0.68      0.80      0.73       458\n",
      "\n",
      "    accuracy                           0.75     43435\n",
      "   macro avg       0.66      0.67      0.66     43435\n",
      "weighted avg       0.76      0.75      0.76     43435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(metrics.classification_report(y_valid, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'tuple'> containing values of types {\"<class 'numpy.ndarray'>\", '(<class \\'dict\\'> containing {\"<class \\'str\\'>\"} keys and {\"<class \\'int\\'>\"} values)', '(<class \\'dict\\'> containing {\"<class \\'str\\'>\"} keys and {\"<class \\'numpy.ndarray\\'>\"} values)'}), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-93c815eede5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_RNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_Glove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    969\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \"input: {}, {}\".format(\n\u001b[1;32m--> 971\u001b[1;33m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[0;32m    972\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'tuple'> containing values of types {\"<class 'numpy.ndarray'>\", '(<class \\'dict\\'> containing {\"<class \\'str\\'>\"} keys and {\"<class \\'int\\'>\"} values)', '(<class \\'dict\\'> containing {\"<class \\'str\\'>\"} keys and {\"<class \\'numpy.ndarray\\'>\"} values)'}), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "prediction = model_RNN.predict(X_test_Glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(prediction, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
